{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958847d0",
   "metadata": {},
   "source": [
    "El siguiente proyecto busca crear una herramienta para tener una referencia del comportamiento de precio de articulos de supermercado, de esta manera poder predecir si el valor de un producto podria tender a la suba, baja o mantenerse en funcion del historico del mismo en una serie temporal.\n",
    "Para esto se inicio el proyecto investigando las cadenas de supermercado que tuvieran una lista de precio publicada online y que la misma fuera actualizada de forma periodica. Siendo este el caso encontramos, de una lista de 10 cadenas de supermercados,  solo 3 que cumplieran con los requisitos tecnicos para esta investigación. Asi es que se desarrollo un modulo en python que se encargaria a recolectar información de las paginas en cuestion.\n",
    "Modulo: scrapper_lxml.ipynb\n",
    "Para esto se utilizaron mecanismos de request, librerias de beautiful soup,lxml, y de selenium, si bien la opcion de usar selenium es la ultima alternativa que quisimos utilizar, nos vimos forzados a esta ya que mucho del contenido generado por las paginas era dinamico y traido por JS , de manera que el modulo intentara realizar un web scrapping con beautifulsoup y en ultima instancia acudira a la libreria de selenium en caso de fallar.\n",
    "Cada vez que ejecutamos el modulo de web scrapping debemos indicarle por medio de una lista cuales son los articulos que vamos a involucrar en nuestro scrapping, hay que tener en cuenta que para el desarrollo de una serie de tiempo es necesario mantener esa lista estable con los mismos productos, lo que no significa que no pueda ejecutarse el codigo sobre cualquier otro producto y obtener informacion del precio en el momento de la consulta.\n",
    "Posterior a que se ejecute el web scrapping propiamente dicho el modulo insertara los datos recolectados en una base de datos MySQL alojada localmente en un servidor local. El primer objetivo de escalabilidad de este proyecto es poder montar el servidor en la red  para poder disponibilizar la información a cualquiera que quiera usarla.\n",
    "\n",
    "El proceso de web scrapping debera ejecutarse de forma periodica intentando asegurar la mayor cantidad registros no duplicados.\n",
    "\n",
    "En paralelo al proceso de web scrapping se ha desarrollado un modulo para convertir los datos recolectados en la base de datos en informacion mediante sucesivos procedimientos de data cleaning \n",
    "Modulo: convertir_sql_en_data_fulldb.ipynb\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
