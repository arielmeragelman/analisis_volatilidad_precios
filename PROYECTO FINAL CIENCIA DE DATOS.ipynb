{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fae3008",
   "metadata": {},
   "source": [
    "## PROYECTO FINAL CIENCIA DE DATOS\n",
    "## Intituto Superior Politecnico de Cordoba 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1707201",
   "metadata": {},
   "source": [
    "Integrantes:\n",
    "\n",
    "-Battistoni, Alejandra\n",
    "\n",
    "-Lifata, Victor Fabian\n",
    "\n",
    "-Meragelman, Sebastian Ariel\n",
    "\n",
    "-Sanchez, Cristian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d69ba6",
   "metadata": {},
   "source": [
    "El siguiente proyecto busca crear una herramienta para tener una referencia del comportamiento de precio de articulos de supermercado, de esta manera poder predecir si el valor de un producto podria tender a la suba, baja o mantenerse en funcion del historico del mismo en una serie temporal.\n",
    "Para esto se inicio el proyecto investigando las cadenas de supermercado que tuvieran una lista de precio publicada online y que la misma fuera actualizada de forma periodica. Siendo este el caso encontramos, de una lista de 10 cadenas de supermercados,  solo 3 que cumplieran con los requisitos tecnicos para esta investigación. Asi es que se desarrollo un modulo en python que se encargaria a recolectar información de las paginas en cuestion.\n",
    "Modulo: scrapper_lxml.ipynb\n",
    "Para esto se utilizaron mecanismos de request, librerias de beautiful soup,lxml, y de selenium, si bien la opcion de usar selenium es la ultima alternativa que quisimos utilizar, nos vimos forzados a esta ya que mucho del contenido generado por las paginas era dinamico y traido por JS , de manera que el modulo intentara realizar un web scrapping con beautifulsoup y en ultima instancia acudira a la libreria de selenium en caso de fallar.\n",
    "Cada vez que ejecutamos el modulo de web scrapping debemos indicarle por medio de una lista cuales son los articulos que vamos a involucrar en nuestro scrapping, hay que tener en cuenta que para el desarrollo de una serie de tiempo es necesario mantener esa lista estable con los mismos productos, lo que no significa que no pueda ejecutarse el codigo sobre cualquier otro producto y obtener informacion del precio en el momento de la consulta.\n",
    "Posterior a que se ejecute el web scrapping propiamente dicho el modulo insertara los datos recolectados en una base de datos MySQL alojada localmente en un servidor local. El primer objetivo de escalabilidad de este proyecto es poder montar el servidor en la red  para poder disponibilizar la información a cualquiera que quiera usarla.\n",
    "\n",
    "El proceso de web scrapping debera ejecutarse de forma periodica intentando asegurar la mayor cantidad registros no duplicados.\n",
    "\n",
    "En paralelo al proceso de web scrapping se ha desarrollado un modulo para convertir los datos recolectados en la base de datos en informacion mediante sucesivos procedimientos de data cleaning \n",
    "Modulo: convertir_sql_en_data_fulldb.ipynb\n",
    "Este modulo descargara el total de los registros obtenidos referidos al supermercado \"SUPER MAMI\", se decidio realizar la investigación sobre este supermercado por dos motivos:\n",
    "1) Menor cantidad de errores durante el proceso de web scrapping\n",
    "2) Presentan ofertas y descuentos que se aplican de formas bastante diversas y que se volvia muy complicado estandarizar su seguimiento (ej: 80% de descuento en el segundo producto , 3x2, 15% descuento con tarjeta xxx)\n",
    "Este modulo se ejecuta realizando:\n",
    "1) Consulta y descarga de datos desde la base Mysql\n",
    "2) Reformateado de los datos quedando la fecha como indice y cada producto como columna unica\n",
    "3) Descarga por web scrapping del valor del dolar el dia de la ejecucion de la consulta\n",
    "4) Reformateo de los datos obtenidos por web scrapping del precio del dolar\n",
    "5) Eliminar errores de medicion (valores inferiores a un threashold)\n",
    "6) Eliminamos columnas que no tengan suficientes mediciones validas\n",
    "7) Se eliminan productos distintos que tengan el mismo precio entre si medicion a medicion (consideramos que es un mismo articulo con distinta etiqueta)\n",
    "8) Modificamos la dimencion analizada, pasamosde una matriz de precios a una matriz de cambio de valores %\n",
    "9) Eliminamos los productos que no presenten cambio de precio alguna de las mediciones\n",
    "- > Observacion: Seria prudente realizar un nuevo analisis sobre cual deberia ser el threshold del minimo de variaciones aceptables entre todas las mediciones\n",
    "\n",
    "\n",
    "10) Evaluamos la correlacion de los valores\n",
    "\n",
    "11) Cambiamos la dimencion de la matriz, pasamos de variacion de precios a la variacion de precios acumulada\n",
    "\n",
    "12) Trasponemos los valores para convertir las distintas mediciones de cada producto en un feature, y cada producto en un registro\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Modulo CLUSTERIZACION KMEAN.ipynb:\n",
    "Realiza una lectura de los archivos csv generados por el modulo anterior y trabaja el concepto del clusterizado de los datos, buscamos en esta etapa identificar y agrupar comportamientos similares en las variaciones de precio, de esta manera simular un proceso de reducción dimencional de los datos y que en las etapas posteriores podamos trabajar con un conjunto de datos mas reducido y que demande menos tiempo de computo y de programación.\n",
    "Para realizar esto se decidio en una primer instancia utilizar el algoritmo de KMEAN debido a que es el que mayor cantidad de documentación tiene disponible y su adaptación para nuestras necesidades fue muy buena.\n",
    "\n",
    "1) Armamos el conjunto de datos X,Y con los productos como X y sus array de variacion como Y\n",
    "2) Graficamos la curva Elbow para determinar la cantidad de clusters (K) que convendria utilizar\n",
    "3) Obtenemos los centroides para cada grupo para un K determinado (tomamos inicialmente 5 como valor al considerar el comportamiento del punto 2)\n",
    "4) Identificamos que producto es el mas representativo de cada cluster , es decir seria el centroide del grupo\n",
    "5) Exporto la lista a csv para su uso posterior\n",
    "6) Identifico la lista completa de todos los productos que conforman cada cluster\n",
    "7) Producimos un dataframe con los productos y a que cluster corresponde cada uno\n",
    "8) Exporto la informacion a un archivo csv para poder utilizarse a posterior\n",
    "9) Genero funciones para poder ejecutar los puntos 3 al 8 de forma automatica\n",
    "\n",
    "Modulo Kmean_control_grafico.ipynp:\n",
    "Debido a que el resultado del algoritmo de clusterizado no supervizado no puede ser medido con tecnicas automaticas diseñamos un mecanismo de validación que consiste en tomar muestras aleatoreas dentro de cada cluster y graficarlas superpuestas entre si para que por medio de la inspección visual se pueda tomar un valor SUBJETIVO sobre la eficiencia del resultado.\n",
    "Asi es que definimos funciones que nos permitan simplificar el proceso de graficado de cada cluster para distintos valores de K y de esta manera evaluar de mejor manera cual es el valor a considerar.\n",
    "En la ejecución actual (Fecha 20/9/2022) consideramos que es mas eficiente utilizar un valor de K = 6 que un valor de K = 5 , pero esto no deja de ser una observacion subjetiva y que podria variar con cada ejecución ya que son muestras aleatoreas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95fce980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "i=+1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd05b4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
